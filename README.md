# Curriculum-Vitae

# Professional Skills
**Software:**
Python, SQL, Snowflake, AWS, Git, DBT, Looker, Tableau, BigQuery, Databricks, Sagemaker, Pendo, Figma, OpenShot, Photoshop, Blender, Microsoft Office.

**Python Libraries:**
Pandas, NumPy, Scikit-learn, TensorFlow, Keras, Hugging Face, NLTK, Gensim, Transfer Learning, Matplotlib, Seaborn, Beautiful Soup, Selenium.

**Data Science:**
Data Analysis, Visualisation & Cleaning, Modelling (supervised & unsupervised), Deep Learning, Time Series, Natural Language Processing, Database Handling, Web Scraping.

**Other Skills:**
Presentations, Client management, Strategy, Product management, Managing junior team members.
Languages - English (native), Italian (native)


# Professional Experience

**Flock, Data Scientist, London**
- Leading pricing Data Scientist, evolving Flock's pricing model through three successful iterations by drawing insights from tens of millions of historic driving data points via advanced analytical tools and modelling methods.
Enhanced the pricing models accuracy by improving APTP (actual price vs technical price), directly impacting pricing strategy for new business.
- Spearheaded research into driving behaviours and crash frequency correlations, yielding critical insights that were fed into the model and helped inform fleet intervention strategies to reduce crash frequency for our customers.
- Investigations into the time to report a claim significantly influenced the setting of one of the company's key objectives, demonstrating that shortening the reporting timeline could greatly benefit the business. Collaborated with the customer success team to identify underperforming fleets and successfully reduced the average time to report from 30 days to under 5 days. This strategic intervention notably improved the business's loss ratio.
- Provided underwriters with telemetry based maps to help them see where fleets are driving and the risk involved in each area, allowing them to price more accurately.
- Collaborated closely with chief strategy, underwriting, and product officers, to harness proprietary data for customer-centric innovations, significantly influencing key business decisions.
- Developed data-centric mechanisms tracking key initiatives and their business impact across several areas of the business.
Modelled new data sources in Snowflake and created impactful dashboards in Looker, empowering different business units with actionable, real-time insights.



**Deloitte Consulting, Data Scientist, HealthTech - R&D Team, London**

- Sole data scientist and head of product building a CTG (monitors a foetal heartbeat during labour) product which warns midwives if intervention is needed. Used rule-based methods to pick out key areas in the time series trace and has an ML prediction element based on the mothers’ physiological features. Worked with MedWay hospital clinicians to develop the product by building a platform for them to tag a gold-standard dataset and co-applying for NHS grant funding.
- Developed a similar proof of concept for ECGs (records the electrical signal from the heart) which flags them as normal or abnormal. A fully ML based approach using convolutional neural networks with an accuracy of 93%.
- Software engineering proof of concept where I built a robotic process automation which reduces administrative burden on GPs. Checked patient blood test records and booked them for either a repeat test or a GP appointment. Successfully received internal Deloitte funding to be built and scaled across the NHS.
- Sole Data Scientist in a 6-month project providing social media insights for a global firm. Wrote code in Python, taking Japanese and Korean social media data off the internet using both web scraping and the Sprinkl API. Built several ML models (NLP) to provide insights such as sentiment, the type of author posting, and where the author sits in the consumer pathway (prospective, advocate, detractor etc.) for both Japanese and Korean. Built and maintained the pipeline code that output the data and used Excel Power Query to provide insights. These insights were presented to the client weekly. 
- Worked closely with Astrazeneca during the release of the Covid Vaccine providing data insights on adverse events reporting, helping their Head of Vaccine safety prepare data insights for press conferences and internal stakeholder meetings.

**HaiX.ai, Data Science Researcher, London** 
- Built sentiment analysis algorithms in Python and on AWS that predicted positive, negative and neutral sentiment towards companies on social media.
Data taken from social media via APIs and web scraping and models built for several European languages.

**BioBeats, NLP Researcher, London** 
- Worked with the CTO and research team to implement NLP classification of anxiety and depression of users within their BioBeats platform. Used real clinical anonymised datasets, written in Python and hosted on AWS. 

**General Assembly, Data Science Immersive, London** 
- Data cleaning, analysing & modelling - several individual projects using multiple ML techniques; regression, classification, SVM, KNN, XGBoost, deep learning etc. 
- Individual capstone project spanning six weeks consisted of predicting different mental health disorders from Reddit submissions using Natural Language Processing.
- Classification of four classes (depression, anxiety, suicide & bipolar) with accuracy of 15% above baseline.
- 1 million reddit posts were scraped from the internet using Beautiful Soup and were then cleaned ready for modelling. 
- Used advanced NLP techniques such as Word2Vec (Gensim). Trained using a variety of different models but the best results were achieved using transfer learning (BERT). 


# Education
**Masters of Electrical and Electronic Engineering, University of Bristol, 1st Class Honours**
- Final year research project, 74%: Application of Machine Learning in Heterogeneous Telecommunication Networks - Q-learning to predict the shortest path for data packets within a Software Defined Network. 
- Developed a deep understanding of both reinforcement learning and TensorFlow. 
- Third year project, 72% team project to build a Rubik’s cube robot which could shuffle, scan, and solve a cube in less than 30 seconds, code written in Python.


# Certifications & Side Projects 
- Databricks Bootcamp London
- Udemy – Deep Learning A-Z: Hands-On Artificial Neural Networks
- GivGiv, Co-Founder – Charity giving app
- Kaggle – Real or Not? NLP with Disaster Tweets
- StayAhead Training – Python Programming Levels 1 & 2
- Coursera – Machine Learning with TensorFlow on Google Cloud Platform
- NZSIA Ski Level 2 Instructor, Levels 1 & 2, New Zealand
